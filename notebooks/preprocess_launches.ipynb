{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launches Data Preprocessing Notebook üöÄüëΩüè∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[!WARNING]  \n",
    "Download the data before running this notebook. Check the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading üì•\n",
    "\n",
    "In this cell, we load the launches raw datasets:\n",
    "\n",
    "- **Launches Data:** Loaded from a JSON file.\n",
    "- **Launchpads Data:** Loaded from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# SETUP: Define output directory relative to this script\n",
    "# ============================================================\n",
    "# Get the absolute path of the directory where this script is located\n",
    "# In a notebook, __file__ is not defined so we use os.getcwd() as a fallback.\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "# Define the folder where raw data is stored (assumed to be \"../data/raw\")\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"raw\")\n",
    "\n",
    "# Define the folder where processed data will be saved (assumed to be \"../data/processed\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "\n",
    "# Build the absolute paths for each dataset\n",
    "spacex_launches_path = os.path.join(RAW_DIR, \"spacex_launches.json\")\n",
    "spacex_launchpads_path = os.path.join(RAW_DIR, \"spacex_launchpads.json\")\n",
    "\n",
    "# Load SpaceX launches data from JSON using the absolute path\n",
    "with open(spacex_launches_path, \"r\") as f:\n",
    "    launches = json.load(f)\n",
    "\n",
    "# Load SpaceX launches data from JSON using the absolute path\n",
    "with open(spacex_launchpads_path, \"r\") as f:\n",
    "    launchpads = json.load(f)\n",
    "\n",
    "print(\"‚úÖ Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Latitude and Longitude and Fixing Datetime Format for Lauches and Lauchpads Data üìÜüìç\n",
    "\n",
    "The following cells will execute:\n",
    "\n",
    "1. Manually creates latitude and longitude data based on reseach and google maps.\n",
    "2. Creates a function to standarize datetime.\n",
    "3. For each launch, assign a specific latitude and longitude based on the launchpad_id.\n",
    "4. For each launchpad, assign a specific latitude and longitude based on its id.\n",
    "5. Save files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are only 5 launchpads we are going to manually address their latitude and longitude\n",
    "# Latitude and longitude extracted from google maps\n",
    "# dict_lat_lon = {launchpad_id: (lat, lon)}\n",
    "lat_lon = {\n",
    "    \"5e9e4501f5090910d4566f83\": (34.64039313749651, -120.58939191725148),\n",
    "    \"5e9e4501f509094ba4566f84\": (28.562259557233922, -80.57734574817835),\n",
    "    \"5e9e4502f5090995de566f86\": (9.047966704576721, 167.74304956933793),\n",
    "    \"5e9e4502f509092b78566f87\": (34.63213232147929, -120.61065970375805),\n",
    "    \"5e9e4502f509094188566f88\": (28.609361333259177, -80.60464369777084),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_datetime(iso_str):\n",
    "    \"\"\"\n",
    "    Convert an ISO datetime string like \"2006-03-24T22:30:00.000Z\"\n",
    "    to the format \"MM/DD/YYYY HH:MM\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = datetime.strptime(iso_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    except ValueError:\n",
    "        # Fallback if microseconds are not provided:\n",
    "        dt = datetime.strptime(iso_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return dt.strftime(\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceX launches updated with lat/lon! üìç\n"
     ]
    }
   ],
   "source": [
    "# Process each launch record\n",
    "for launch in launches:\n",
    "    # Convert the datetime from ISO to \"MM/DD/YYYY HH:MM\" format\n",
    "    if \"date\" in launch:\n",
    "        launch[\"date\"] = convert_datetime(launch[\"date\"])\n",
    "    \n",
    "    # Assign latitude and longitude based on launchpad_id if available in the dictionary\n",
    "    launchpad_id = launch.get(\"launchpad_id\")\n",
    "    launch[\"lat\"], launch[\"lon\"] = lat_lon[launchpad_id]\n",
    "\n",
    "print(\"SpaceX launches updated with lat/lon! üìç\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceX launchpads updated with lat/lon! üìç\n"
     ]
    }
   ],
   "source": [
    "# Process each launchpad record\n",
    "for launchpad in launchpads:\n",
    "    lp_id = launchpad.get(\"id\")\n",
    "    if lp_id in lat_lon:\n",
    "        launchpad[\"lat\"], launchpad[\"lon\"] = lat_lon[lp_id]\n",
    "    else:\n",
    "        # Assign none if there's no id match\n",
    "        launchpad[\"lat\"], launchpad[\"lon\"] = None, None\n",
    "        \n",
    "print(\"SpaceX launchpads updated with lat/lon! üìç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Processed Lauches and Launchpads Data üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved processed launches dataset!\n",
      "üíæ Saved processed launchpads dataset!\n"
     ]
    }
   ],
   "source": [
    "# Build the absolute path for the output file\n",
    "launches_processed_path = os.path.join(PROCESSED_DIR, \"launches_processed.json\")\n",
    "launchpads_processed_path = os.path.join(PROCESSED_DIR, \"launchpads_processed.json\")\n",
    "\n",
    "# Save the updated launches back to a JSON file (no spaces, no identation)\n",
    "with open(launches_processed_path, \"w\") as f:\n",
    "    json.dump(launches, f, separators=(',', ':'))\n",
    "\n",
    "print(\"üíæ Saved processed launches dataset!\")\n",
    "\n",
    "# Save the updated launchpads back to a JSON file (no spaces, no identation)\n",
    "with open(launchpads_processed_path, \"w\") as f:\n",
    "    json.dump(launchpads, f, separators=(',', ':'))\n",
    "\n",
    "print(\"üíæ Saved processed launchpads dataset!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
