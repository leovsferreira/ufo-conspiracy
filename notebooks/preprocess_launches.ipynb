{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launches Data Preprocessing Notebook üöÄüëΩüè∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "‚ö†Ô∏è Download the data before running this notebook. Check the documentation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading üì•\n",
    "\n",
    "In this cell, we load the launches raw dataset:\n",
    "\n",
    "- **Launches Data:** Loaded from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2700 launches from raw data.\n",
      "‚úÖ Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# SETUP: Define output directory relative to this script\n",
    "# ============================================================\n",
    "# Get the absolute path of the directory where this script is located\n",
    "# In a notebook, __file__ is not defined so we use os.getcwd() as a fallback.\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "# Define the folder where raw data is stored (assumed to be \"../data/raw\")\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"raw\")\n",
    "\n",
    "# Define the folder where processed data will be saved (assumed to be \"../data/processed\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "OUTPUT_FILE = os.path.join(PROCESSED_DIR, \"spacedevs_launches_processed.json\") # Build the absolute path for the output file\n",
    "\n",
    "# Build the absolute paths for each dataset\n",
    "launches_path = os.path.join(RAW_DIR, \"spacedevs_launches.json\")\n",
    "\n",
    "# Load SpaceX launches data from JSON using the absolute path\n",
    "with open(launches_path, \"r\") as f:\n",
    "    launches = json.load(f)\n",
    "\n",
    "# Extract the list of launches; ignore the \"offset\" for cleaning purposes.\n",
    "results = launches.get(\"results\", [])\n",
    "print(f\"Loaded {len(results)} launches from raw data.\")\n",
    "\n",
    "print(\"‚úÖ Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Datetime Format for Lauches Data üìÜüìç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_datetime(iso_str):\n",
    "    \"\"\"\n",
    "    Convert an ISO datetime string like \"2006-03-24T22:30:00.000Z\"\n",
    "    to the format \"MM/DD/YYYY HH:MM\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = datetime.strptime(iso_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    except ValueError:\n",
    "        # Fallback if microseconds are not provided:\n",
    "        dt = datetime.strptime(iso_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return dt.strftime(\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Only Relevant Variables From Raw Data üìÜüìç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessed 2700 launches!\n"
     ]
    }
   ],
   "source": [
    "# Create list to append processed launches\n",
    "processed_launches = []\n",
    "\n",
    "for launch in results:\n",
    "    processed = {}\n",
    "    processed[\"id\"] = launch.get(\"id\")\n",
    "    processed[\"name\"] = launch.get(\"name\")\n",
    "    \n",
    "    net = launch.get(\"net\")\n",
    "    processed[\"net\"] = convert_datetime(net) if net else None\n",
    "    \n",
    "    # Extract status name from the nested status object, using a fallback empty dict if needed.\n",
    "    status = launch.get(\"status\") or {}\n",
    "    processed[\"status\"] = status.get(\"abbrev\")\n",
    "    \n",
    "    # Extract rocket id from the nested rocket object.\n",
    "    rocket = launch.get(\"rocket\") or {}\n",
    "    processed[\"rocket_id\"] = rocket.get(\"id\")\n",
    "    \n",
    "    # Extract pad details: id, name, latitude, and longitude.\n",
    "    pad = launch.get(\"pad\") or {}\n",
    "    processed[\"pad\"] = {\n",
    "        \"id\": pad.get(\"id\"),\n",
    "        \"name\": pad.get(\"name\"),\n",
    "        \"latitude\": pad.get(\"latitude\"),\n",
    "        \"longitude\": pad.get(\"longitude\")\n",
    "    }\n",
    "    \n",
    "    # Extract mission details: name, type, and description.\n",
    "    mission = launch.get(\"mission\") or {}\n",
    "    processed[\"mission\"] = {\n",
    "        \"name\": mission.get(\"name\"),\n",
    "        \"type\": mission.get(\"type\"),\n",
    "        \"description\": mission.get(\"description\")\n",
    "    }\n",
    "    \n",
    "    # Extract launch service provider info.\n",
    "    lsp = launch.get(\"launch_service_provider\") or {}\n",
    "    processed[\"launch_service_provider\"] = {\n",
    "        \"id\": lsp.get(\"id\"),\n",
    "        \"name\": lsp.get(\"name\")\n",
    "    }\n",
    "    \n",
    "    # Keep the URL for more info.\n",
    "    processed[\"url\"] = launch.get(\"url\")\n",
    "    \n",
    "    processed_launches.append(processed)\n",
    "\n",
    "print(f\"‚úÖ Preprocessed {len(processed_launches)} launches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Processed Lauches and Launchpads Data üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved processed launches dataset!\n"
     ]
    }
   ],
   "source": [
    "# Save the updated launches back to a JSON file (no spaces, no identation)\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    json.dump(processed_launches, f, separators=(',', ':'))\n",
    "\n",
    "print(\"üíæ Saved processed launches dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Some Preliminar Analysis on the Processed Launches üìâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
