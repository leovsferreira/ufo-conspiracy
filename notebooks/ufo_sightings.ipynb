{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celestial Conspiracies: UFOs, SpaceX, and Military Bases üöÄüëΩüè∞\n",
    "\n",
    "In this notebook we will:\n",
    "- **Load** and examine our processed datasets:\n",
    "  - `ufo_processed.csv`\n",
    "  - `pacedevs_launches_processed.json`\n",
    "  - `military_bases.csv`\n",
    "- **Flag** UFO sightings:\n",
    "  - **is_near_spacex_launch:** UFO sighting occurred within 24 hours after a launch and within 50 km of the launch location.\n",
    "  - **is_near_military:** UFO sighting occurred within 50 km of a military base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading üì•\n",
    "\n",
    "In this cell, we load:\n",
    "\n",
    "- **Launches Data:** Loaded from a JSON file.\n",
    "- **UFO Data:** Loaded from a CSV file.\n",
    "- **U.S. Military Bases Data:** Loaded from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# SETUP: Define output directory relative to this script\n",
    "# ============================================================\n",
    "# Get the absolute path of the directory where this script is located\n",
    "# In a notebook, __file__ is not defined so we use os.getcwd() as a fallback.\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "# Define the folder where raw data is stored (assumed to be \"../data/raw\")\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"raw\")\n",
    "\n",
    "# Define the folder where raw data is stored (assumed to be \"../data/raw\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"..\", \"data\", \"processed\")\n",
    "\n",
    "# Load our datasets\n",
    "ufo_path = os.path.join(PROCESSED_DIR, \"ufo_processed.csv\")\n",
    "launches_path = os.path.join(PROCESSED_DIR, \"spacedevs_launches_processed.json\")\n",
    "military_path = os.path.join(RAW_DIR, \"military_bases.csv\")\n",
    "\n",
    "# Load UFO data\n",
    "ufo_df = pd.read_csv(ufo_path)\n",
    "# Convert the UFO datetime string into a datetime object for easier comparison\n",
    "ufo_df['datetime'] = pd.to_datetime(ufo_df['datetime'], format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "# Load SpaceX launches data\n",
    "with open(launches_path, \"r\") as f:\n",
    "    launches = json.load(f)\n",
    "launches_df = pd.DataFrame(launches)\n",
    "# Convert the launch \"net\" string into datetime object.\n",
    "launches_df['net'] = pd.to_datetime(launches_df['net'], format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "# Load military bases data\n",
    "# Note: The military bases CSV is delimited by semicolons.\n",
    "military_df = pd.read_csv(military_path, delimiter=\";\")\n",
    "\n",
    "print(\"‚úÖ All datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data By Time and Location ‚åöüìå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Our launches dataset apparently have launches that are going to happen in the future\n",
    "# We need to exclude them from our evaluation\n",
    "# Start by getting today's datetime\n",
    "current_datetime = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Use loc to keep only present and past launches\n",
    "launches_df = launches_df.loc[launches_df['net'] <= current_datetime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this analysis, we are going to use only USA data\n",
    "def is_united_states(pad):\n",
    "    # Check if pad is a valid dictionary\n",
    "    if not isinstance(pad, dict):\n",
    "        return False\n",
    "    country = pad.get('country')\n",
    "    # Check if country is a valid dictionary\n",
    "    if not isinstance(country, dict):\n",
    "        return False\n",
    "    # Get the alpha code, defaulting to an empty string if not found\n",
    "    alpha_code = country.get('alpha_3_code', '')\n",
    "    return alpha_code.lower() == \"usa\"\n",
    "\n",
    "\n",
    "print(f\"Size before selecting only the United States: {launches_df.size}\")\n",
    "\n",
    "# Select only records which the country alpha code is 'USA'\n",
    "launches_df = launches_df[launches_df['pad'].apply(is_united_states)]\n",
    "\n",
    "print(f\"Size after selecting only the United States: {launches_df.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our UFO dataset also needs to contain only registers that happened within the USA\n",
    "print(f\"Size before selecting only the United States: {ufo_df.size}\")\n",
    "\n",
    "# Only keep UFO sightings within the USA\n",
    "ufo_df = ufo_df[ufo_df['country'] == 'USA']\n",
    "\n",
    "# Drop values if either latitude or longitude are NaN\n",
    "ufo_df = ufo_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(f\"Size after selecting only the United States: {ufo_df.size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
